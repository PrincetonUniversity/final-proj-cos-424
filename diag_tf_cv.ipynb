{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idempotent data loading. For a given chromosome n (a string).\n",
      "    \n",
      "    Returns (train_df, test_df, train_ix, test_ix, train_tissues, tfs)\n",
      "    \n",
      "    The first two are the train and test dataframes, and test_ix are the\n",
      "    values in test_df['assayed'] that are missing and need to be imputed (with the\n",
      "    correct answer being in test_df['filled'] in the corresponding locations.\n",
      "    train_ix are the assayed (known) methylation values from limited microarray\n",
      "    sampling (e.g., test_df['assayed'].iloc[train_ix] can be used for prediction of\n",
      "    test_df['filled'].iloc[test_ix], and the former should be about equal to\n",
      "    test_df['filled'].iloc[train_ix] (two different ways of sampling methylation).\n",
      "    \n",
      "    Imports genetic context and adds those columns to the parameter df, returning\n",
      "    a merged one. tfs is the list of names of new transcription\n",
      "    factors.\n",
      "    \n",
      "    train_tissues is a list of the names of columns with chromosome methylation values.\n",
      "    \n",
      "    Note that loading from scratch may take ~5 min (for merging genetic contexts).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f019cffff10>> ignored\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import *\n",
    "import sklearn\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import scipy\n",
    "from joblib import Parallel, delayed\n",
    "import threading\n",
    "nproc = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "if 'utils' not in sys.path:\n",
    "    sys.path.append('utils')\n",
    "\n",
    "import data_loader\n",
    "\n",
    "# Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Idempotent, cached data retrieval script\n",
    "\n",
    "print(data_loader.load_chromosome.__doc__)\n",
    "train_df, test_df, train_ix, test_ix, train_tissues, tfs = \\\n",
    "    data_loader.load_chromosome_cached('1')\n",
    "    \n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nans in mean-imputed 0\n",
      "nans in interpolated 0\n"
     ]
    }
   ],
   "source": [
    "# Perhaps there are obvious sequence trends?\n",
    "def local_impute(data):\n",
    "    #http://stackoverflow.com/questions/9537543/replace-nans-in-numpy-array-with-closest-non-nan-value\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data[~mask])\n",
    "    return data\n",
    "\n",
    "# Do mean imputation on our training data.\n",
    "def mean_impute(data):\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = float(data.mean()) # just = m messes with serialization\n",
    "    return data\n",
    "train_df_imp = train_df\n",
    "train_df_int = train_df\n",
    "for i in train_tissues:\n",
    "    train_df_imp[i] = mean_impute(train_df[i].copy())\n",
    "    train_df_int[i] = local_impute(train_df[i].copy())\n",
    "print('nans in mean-imputed', np.isnan(train_df_imp[train_tissues]).sum().sum())\n",
    "print('nans in interpolated', np.isnan(train_df_int[train_tissues]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied pretty much directly from sklearn\n",
    "\n",
    "# Returns a TensorFlow scalar with the size of the i-th dimension for\n",
    "# the parameter tensor x.\n",
    "def tf_get_shape(x, i):\n",
    "    return tf.squeeze(tf.slice(tf.shape(x), [i], [1])) \n",
    "\n",
    "def tf_nrows(x):\n",
    "    return tf_get_shape(x, 0)\n",
    "\n",
    "def tf_ncols(x):\n",
    "    return tf_get_shape(x, 1)\n",
    "\n",
    "# Simultaneous K-cluster likelihood computation.\n",
    "# X is NxD, mus is KxD, sigmas is KxD\n",
    "# Output is KxN likelihoods for each sample in each cluster.\n",
    "def tf_log_normals(X, mus, sigmas):\n",
    "    # p(X) = sqrt(a * b * c)\n",
    "    # a = (2 pi)^(-p)\n",
    "    # b = det(sigma)^(-1)\n",
    "    # c = exp(-(x - mu)^T sigma^(-1) (x - mu)) [expanded for numerical stability]\n",
    "    #\n",
    "    # Below we make simplifications since sigma is diag\n",
    "    \n",
    "    D = tf_ncols(mus)\n",
    "    XT = tf.transpose(X) # pxN\n",
    "    invsig = tf.inv(sigmas)\n",
    "    \n",
    "    loga = -tf.cast(D, 'float64') * tf.log(tf.constant(2 * np.pi, dtype='float64')) # scalar\n",
    "    logb = tf.reduce_sum(tf.log(invsig), 1, keep_dims=True) # Kx1\n",
    "    logc =  \\\n",
    "        - tf.reduce_sum(invsig * tf.square(mus), 1, keep_dims=True) \\\n",
    "        + 2 * tf.matmul(invsig * mus, XT) \\\n",
    "        - tf.matmul(invsig, tf.square(XT)) # KxN\n",
    "    \n",
    "    return 0.5 * (loga + logb + logc)\n",
    "\n",
    "# Stably log-sum-exps likelihood along rows.\n",
    "# Reduces KxN tensor L to 1xN tensor\n",
    "def tf_log_sum_exp(L):\n",
    "    maxs = tf.reduce_max(L, 0, keep_dims=True) # 1xN\n",
    "    return tf.log(tf.reduce_sum(tf.exp(L - maxs), 0, keep_dims=True)) + maxs\n",
    "\n",
    "# X is NxD, mus is KxD, sigmas KxD, alphas is K\n",
    "# output is KxN log likelihoods.\n",
    "def tf_log_likelihood(X, mus, sigmas, alphas):\n",
    "    alphas = tf.expand_dims(alphas, 1) # Kx1\n",
    "    return tf_log_normals(X, mus, sigmas) + tf.log(alphas) # KxN\n",
    "\n",
    "# X is NxD, mus is KxD, sigmas KxD, alphas is K\n",
    "# output is 1xN log probability for each sample, KxN responsibilities\n",
    "def estep(X, mus, sigmas, alphas):\n",
    "    log_likelihoods = tf_log_likelihood(X, mus, sigmas, alphas)\n",
    "    sample_log_prob = tf_log_sum_exp(log_likelihoods) # 1xN\n",
    "    return sample_log_prob, tf.exp(log_likelihoods - sample_log_prob)\n",
    "\n",
    "EPS = np.finfo(float).eps\n",
    "MIN_COVAR = 0.1\n",
    "# X is NxD, resp is KxN (and normalized along axis 0)\n",
    "# Returns maximize step means, covariance, and cluster priors,\n",
    "# which have dimension KxD, KxD, and K, respectively\n",
    "def mstep(X, resp):\n",
    "    weights = tf.reduce_sum(resp, 1) # K\n",
    "    invweights = tf.expand_dims(tf.inv(weights + 10 * EPS), 1) # Kx1\n",
    "    alphas = EPS + weights / (tf.reduce_sum(weights) + 10 * EPS) # K\n",
    "    weighted_cluster_sum = tf.matmul(resp, X) # KxD \n",
    "    mus = weighted_cluster_sum * invweights\n",
    "    avg_X2 = tf.matmul(resp, tf.square(X)) * invweights\n",
    "    avg_mu2 = tf.square(mus)\n",
    "    avg_X_mu = mus * weighted_cluster_sum * invweights\n",
    "    sigmas = avg_X2 - 2 * avg_X_mu + avg_mu2 + MIN_COVAR\n",
    "    # (x - mu) (x-mu)^T for banded. \n",
    "    return mus, sigmas, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual likelihoods [[ 0.55608512  0.83276787  0.3352924   0.53247019  0.8850091 ]\n",
      " [ 0.00546339  0.02183937  0.00645537  0.00612281  0.01459697]\n",
      " [ 0.43845149  0.14539276  0.65825223  0.461407    0.10039392]]\n",
      "log likelihoods    [[ 0.55608512  0.83276787  0.3352924   0.53247019  0.8850091 ]\n",
      " [ 0.00546339  0.02183937  0.00645537  0.00612281  0.01459697]\n",
      " [ 0.43845149  0.14539276  0.65825223  0.461407    0.10039392]]\n",
      "K=0 rmse=2.9373740229761033e-16\n",
      "K=1 rmse=2.854661289398182e-17\n",
      "K=2 rmse=2.4763200404893063e-16\n"
     ]
    }
   ],
   "source": [
    "# Make sure N, D are small so the numerically unstable verification code\n",
    "# doesn't underflow.\n",
    "N = 5\n",
    "D = 10\n",
    "\n",
    "X = np.random.normal(size=(N, D))\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "mus = np.array([mu, mu, mu * 2])\n",
    "sigmas = np.array([sigma, sigma * 2, sigma])\n",
    "K = len(sigmas)\n",
    "alphas = np.random.dirichlet(np.ones(K), 1)[0]\n",
    "\n",
    "mean_ll, resp = sess.run(estep(*(tf.constant(x) for x in (X, mus, sigmas, alphas))))\n",
    "def normal_likelihoods(X, mu, sigma):\n",
    "    exponent = -np.dot((X - mu[np.newaxis, :]) ** 2, 1 / sigma) / 2\n",
    "    return (2 * np.pi) ** (-D / 2) * np.prod(sigma) ** (-1 / 2) * np.exp(exponent)\n",
    "actual = np.array([normal_likelihoods(X, mu, sigma) for mu, sigma in zip(mus, sigmas)])\n",
    "actual = sklearn.preprocessing.normalize(actual * alphas[:, np.newaxis], norm='l1', axis=0)\n",
    "resp = sklearn.preprocessing.normalize(resp, norm='l1', axis=0)\n",
    "print('actual likelihoods', actual)\n",
    "print('log likelihoods   ', resp)\n",
    "rmses = np.sqrt(sklearn.metrics.mean_squared_error(actual.T, resp.T, multioutput='raw_values'))\n",
    "for i, rmse in enumerate(rmses):\n",
    "    print('K={} rmse={}'.format(i, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar pattern to\n",
    "# https://gist.github.com/narphorium/d06b7ed234287e319f18\n",
    "\n",
    "#todo try initializing covar to emprical cv computed from kmeans labels\n",
    "\n",
    "# Runs up to max_steps EM iterations, stopping earlier if log likelihood improves\n",
    "# less than tol.\n",
    "# X should be an NxD data matrix, initial_mus should be KxD\n",
    "# max_steps should be an int, tol should be a float.\n",
    "def fit_em(X, initial_mus, max_steps, tol, sess):\n",
    "    N, D = X.shape\n",
    "    K, Dmu = initial_mus.shape\n",
    "    assert D == Dmu\n",
    "        \n",
    "    mus0 = initial_mus\n",
    "    sigmas0 = np.tile(np.var(X, axis=0), (K, 1))\n",
    "    alphas0 = np.ones(K) / K\n",
    "    X = tf.constant(X)\n",
    "    \n",
    "    mus, sigmas, alphas = (tf.Variable(x, dtype='float64') for x in [mus0, sigmas0, alphas0])\n",
    "    \n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    all_ll, resp = estep(X, mus, sigmas, alphas)\n",
    "    cmus, csigmas, calphas = mstep(X, resp)\n",
    "    update_mus_step = tf.assign(mus, cmus)\n",
    "    update_sigmas_step = tf.assign(sigmas, csigmas)\n",
    "    update_alphas_step = tf.assign(alphas, calphas)     \n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "    ll = prev_ll = -np.inf\n",
    "                         \n",
    "    with tf.Session() as sess2:\n",
    "        sess2.run(init_op)\n",
    "        for i in range(max_steps):\n",
    "            ll = sess2.run(tf.reduce_mean(all_ll))\n",
    "            sess2.run((update_mus_step, update_sigmas_step, update_alphas_step))\n",
    "            print('EM iteration', i, 'log likelihood', ll)\n",
    "            if abs(ll - prev_ll) < tol:\n",
    "                break\n",
    "            prev_ll = ll\n",
    "        m, s, a = sess2.run((mus, sigmas, alphas))\n",
    "    \n",
    "    return ll, m, s, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a set of partial observations xs each of dimension O < D for a fitted GMM model with \n",
    "# K cluster priors alpha, KxD means mus, and KxD diagonal covariances sigmas,\n",
    "# returns the weighted sum of normals for the remaining D - O dimensions.\n",
    "#\n",
    "# Returns posterior_mus, posterior_sigmas, posterior_prior,\n",
    "# of dimensions:\n",
    "# Kx(D-O), Kx(D-O), NxK, respectively (each mu, sigma is the same for all posteriors).\n",
    "# NxK, NxKxD, NxKxD, respectively, for each x in xs, total of N.\n",
    "def marginal_posterior(xs, mus, sigmas, alphas, sess):\n",
    "    # https://gbhqed.wordpress.com/2010/02/21/conditional-and-marginal-distributions-of-a-multivariate-gaussian/\n",
    "    # diagonal case is easy:\n",
    "    # https://en.wikipedia.org/wiki/Schur_complement#Applications_to_probability_theory_and_statistics\n",
    "    O = xs.shape[1]\n",
    "    D = mus.shape[1]\n",
    "    observed_mus, observed_sigmas = (tf.constant(a, dtype='float64')\n",
    "                                     for a in (mus[:,0:O], sigmas[:, 0:O]))\n",
    "    ll = tf_log_likelihood(xs, observed_mus, observed_sigmas, alphas) # KxN\n",
    "    norm = tf_log_sum_exp(ll) # 1xN\n",
    "    ll, norm = sess.run((ll, norm))\n",
    "    return mus[:, O:D], sigmas[:, O:D], np.transpose(ll / norm)\n",
    "\n",
    "# A \"sparser\" estimate which just uses the most likely cluster's mean as the estimate.\n",
    "def argmax_exp(mus, sigmas, alphas):\n",
    "    i = np.argmax(alphas)\n",
    "    return mus[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_em() missing 1 required positional argument: 'sess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0551c63bcaf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_pdf.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_em\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_em() missing 1 required positional argument: 'sess'"
     ]
    }
   ],
   "source": [
    "n_samples = 25\n",
    "np.random.seed(0)\n",
    "\n",
    "def MVN(shear, shift):\n",
    "    rs = np.random.randn(n_samples, 2)\n",
    "    return np.dot(rs, shear.T) + shift\n",
    "G1 = MVN(np.identity(2), np.array([20, 20]))\n",
    "G2 = MVN(np.array([[0., 3.5], [-0.7, .7]]), np.zeros(2))\n",
    "G3 = MVN(np.array([[-1, 0.8], [0, 4]]), np.array([10, 8]))\n",
    "\n",
    "# concatenate the two datasets into the final training set\n",
    "X = np.vstack([G1, G2, G3])\n",
    "rx = np.random.choice(range(len(X)), 3, replace=False)\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_pdf.html\n",
    "_, m, s, a = fit_em(X, X[rx], 100, EPS)\n",
    "x = np.linspace(-20.0, 30.0)\n",
    "y = np.linspace(-20.0, 40.0)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "pts = np.array([xx.ravel(), yy.ravel()]).T\n",
    "ll = -estep(pts, m, s, a)[0].eval()\n",
    "print('means\\n{}\\ncov\\n{}\\ncluster priors\\n{}'.format(m, s, a))\n",
    "CS = plt.contour(xx, yy, ll.reshape(xx.shape), norm=LogNorm(vmin=1.0, vmax=1000.0),\n",
    "                levels=np.logspace(0, 3, 20))\n",
    "plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-150a937ab6b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Reverse m, s, a, since we know 'y'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarginal_posterior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "# Make this into a nice image.\n",
    "ys = [-10, 0, 2.5, 10, 20]\n",
    "pts = np.arange(-20, 30, 0.1, dtype='float64').reshape(-1, 1)\n",
    "ys = np.array(ys, dtype='float64').reshape(-1, 1)\n",
    "# Reverse m, s, a, since we know 'y'\n",
    "mr, sr = (x[:, ::-1] for x in (m, s))\n",
    "mm, sm, ams = marginal_posterior(ys, mr, sr, a)\n",
    "for i, y in enumerate(ys.reshape(-1)):\n",
    "    print('y =', y)\n",
    "    ll = estep(pts, mm, sm, ams[i])[0].eval().reshape(-1)\n",
    "    plt.plot(pts, np.exp(ll) / 10 + y)\n",
    "    #plt.show()\n",
    "\n",
    "ys = np.arange(-20, 30, 0.05, dtype='float64').reshape(-1, 1)\n",
    "mm, sm, ams = marginal_posterior(ys, mr, sr, a)\n",
    "xs = [argmax_exp(mm, sm, am) for am in ams]\n",
    "plt.plot(xs, ys, label='argmax cluster mu')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 379551)\n"
     ]
    }
   ],
   "source": [
    "# N = 10\n",
    "N = 33\n",
    "p = 20 # D is better?\n",
    "K = 6\n",
    "k = 0 # maximum band offset (0 is just diagonal)\n",
    "tissues_to_cluster = train_tissues\n",
    "X_np = train_df_imp[train_tissues].values.transpose()\n",
    "\n",
    "np.random.seed(2)\n",
    "rc = np.random.choice(range(len(train_df)), D, replace=False)\n",
    "rmu = np.random.choice(range(N), K, replace=False)\n",
    "\n",
    "np.random.shuffle(X_np)\n",
    "per = N // K\n",
    "splits = [X_np[i:i+per] for i in range(0, N // K * K, per)]\n",
    "\n",
    "\n",
    "# X_trunc = X_np[:N, rc]\n",
    "X_trunc = X_np[:N]\n",
    "mu_init = X_trunc[rmu]\n",
    "# mu_init = np.array([x.mean(axis=0) for x in splits])\n",
    "#mu_init = X_np[19:22]\n",
    "\n",
    "\n",
    "print(mu_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 379551)\n"
     ]
    }
   ],
   "source": [
    "print(X_np.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_em() missing 1 required positional argument: 'sess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ce50d3973b33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#todo kmeans warmup (just in numpy?)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#todo mincovar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_em\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m print('mean log likelihood\\n{}\\nmeans\\n{}\\ncov\\n{}\\ncluster priors\\n{}'\n\u001b[0;32m      8\u001b[0m       .format(lp, m, s, a))\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_em() missing 1 required positional argument: 'sess'"
     ]
    }
   ],
   "source": [
    "## Implement custom GMM\n",
    "#todo check float32/float64 conversion for speedup\n",
    "#todo scale (standardize) data before running\n",
    "#todo kmeans warmup (just in numpy?)\n",
    "#todo mincovar\n",
    "lp, m, s, a = fit_em(X_trunc, mu_init, 100, EPS)\n",
    "print('mean log likelihood\\n{}\\nmeans\\n{}\\ncov\\n{}\\ncluster priors\\n{}'\n",
    "      .format(lp, m, s, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = np.ones(len(train_df))\n",
    "o[train_ix] = 0\n",
    "o[test_ix] = 0\n",
    "unobserved_untested_ix = np.where(o)[0]\n",
    "o = np.zeros(len(train_df))\n",
    "o[test_ix] = 1\n",
    "unobserved_tested_ix = np.where(o)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7523\n",
      "368411\n",
      "3617\n",
      "[  1084   1154   1214 ..., 378792 378806 379168]\n"
     ]
    }
   ],
   "source": [
    "perm = np.hstack((train_ix, unobserved_tested_ix, unobserved_untested_ix))\n",
    "print(len(train_ix))\n",
    "print(len(unobserved_tested_ix))\n",
    "print(len(unobserved_untested_ix))\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7523,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(379551, 379551)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = test_df['filled'][train_ix].values\n",
    "print(observed.shape)\n",
    "len(perm), len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue b0 correlations\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5e579fb62bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_tissues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tissue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'correlations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'    mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "for t in train_tissues:\n",
    "    print('tissue', t, 'correlations')\n",
    "    for i, x in enumerate(m):\n",
    "        print('    mean', i, scipy.stats.pearsonr(x, train_df[t])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2caac1be1806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarginal_posterior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "mm, ms = (x[:, perm] for x in (m, s))\n",
    "print(len(mm[0]), len(ms[0]), len(a))\n",
    "print(observed.reshape(1, len(observed)))\n",
    "print(observed.shape)\n",
    "mm, sm, ams = marginal_posterior(observed.reshape(1, len(observed)), mm, ms, a)\n",
    "print(mm.shape, sm.shape, ams.shape)\n",
    "pred = argmax_exp(mm, sm, ams[0])[:len(unobserved_tested_ix)]\n",
    "print(pred)\n",
    "actual = test_df['filled'][unobserved_tested_ix]\n",
    "print(len(pred), len(actual))\n",
    "# print('rmse', math.sqrt(actual.sub(pred).pow(2).mean())) # rmse of GMM\n",
    "print('rmse', np.sqrt(sklearn.metrics.mean_squared_error(actual, pred)))\n",
    "print('r2', sklearn.metrics.r2_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 372028)\n",
      "(6, 379551)\n",
      "[[ 0.87500975  0.90780635  0.92082692 ...,  0.24740215  0.78194421\n",
      "   0.90912815]\n",
      " [ 0.52923078  0.75415283  0.8416149  ...,  0.31100479  0.73827392\n",
      "   0.50788287]\n",
      " [ 0.69746529  0.68127254  0.86028262 ...,  0.35032036  0.85354664\n",
      "   0.29410567]\n",
      " [ 0.73969412  0.79942736  0.86677642 ...,  0.49964045  0.63410663\n",
      "   0.60784865]\n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " [ 0.62100853  0.67671729  0.74663413 ...,  0.33907529  0.68822959\n",
      "   0.63115047]]\n",
      "[[ 0.12655612  0.10154384  0.16225399 ...,  0.12070368  0.11114377\n",
      "   0.10137775]\n",
      " [ 0.10727508  0.10103835  0.10189376 ...,  0.10701106  0.10095833\n",
      "   0.10569277]\n",
      " [ 0.11274317  0.10009626  0.10057778 ...,  0.1149717   0.10310947\n",
      "   0.12588596]\n",
      " [ 0.10893174  0.10871207  0.14560457 ...,  0.13492641  0.10616518\n",
      "   0.18020341]\n",
      " [ 0.1         0.1         0.1        ...,  0.1         0.1         0.1       ]\n",
      " [ 0.11976167  0.1208131   0.18980543 ...,  0.13622783  0.10435932\n",
      "   0.10029071]]\n"
     ]
    }
   ],
   "source": [
    "print(mm.shape)\n",
    "print(ms.shape)\n",
    "print(mm)\n",
    "print(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 379551)\n",
      "(30, 379551)\n",
      "K: 2, Fold: 0\n",
      "K: 3, Fold: 0\n",
      "K: 4, Fold: 0\n",
      "K: 6, Fold: 0\n",
      "K: 5, Fold: 0\n",
      "K: 7, Fold: 0\n",
      "K: 8, Fold: 0\n",
      "K: 9, Fold: 0\n",
      "K: 10, Fold: 0\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n",
      "(29, 379551)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1d2ce8ae2227>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_K\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mthreads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m# i = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.3/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m                 \u001b[0mdeadline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.3/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# leave one out CV\n",
    "# TODO: change from mean imputation\n",
    "\n",
    "# X_np = X_np[:][:33]\n",
    "# print(X_np.shape)\n",
    "\n",
    "# o = np.ones(len(train_df))\n",
    "# o[train_ix] = 0\n",
    "# o[test_ix] = 0\n",
    "# unobserved_untested_ix = np.where(o)[0]\n",
    "# o = np.zeros(len(train_df))\n",
    "# o[test_ix] = 1\n",
    "# unobserved_tested_ix = np.where(o)[0]\n",
    "# perm = np.hstack((train_ix, unobserved_tested_ix, unobserved_untested_ix))\n",
    "\n",
    "# X_np_perm = X_np[:, perm]\n",
    "\n",
    "print(X_np.shape)\n",
    "X_np_new = X_np[:][:33]\n",
    "X_np_new = np.delete(X_np_new, [14,25,26], 0)\n",
    "print(X_np_new.shape)\n",
    "\n",
    "o = np.ones(len(train_df))\n",
    "o[train_ix] = 0\n",
    "o[test_ix] = 0\n",
    "unobserved_untested_ix = np.where(o)[0]\n",
    "o = np.zeros(len(train_df))\n",
    "o[test_ix] = 1\n",
    "unobserved_tested_ix = np.where(o)[0]\n",
    "\n",
    "perm = np.hstack((train_ix, unobserved_tested_ix, unobserved_untested_ix))\n",
    "X_np_perm = X_np_new[:, perm]\n",
    "args_K = range(2, 11)\n",
    "\n",
    "# these are global variables used in get_avg_r2_cv; don't change\n",
    "rmse_matrix = np.empty((len(args_K), X_np_perm.shape[0]))\n",
    "r2_matrix = np.empty((len(args_K), X_np_perm.shape[0]))\n",
    "\n",
    "def get_avg_r2_cv(K, index):\n",
    "    folds = range(0, X_np_perm.shape[0])\n",
    "    r2_arr = []\n",
    "    rmse_arr = []\n",
    "    for fold in folds: \n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.InteractiveSession()\n",
    "        print(\"K: \" + str(K) + \", Fold: \" + str(fold))\n",
    "        X_test = X_np_perm[fold, :]\n",
    "        X_train = np.delete(X_np_perm, fold, 0)\n",
    "        print(X_train.shape)\n",
    "        rmu = np.random.choice(range(X_train.shape[0]), K, replace=False)\n",
    "        mu_init = X_train[rmu]\n",
    "        lp, m, s, a = fit_em(X_train, mu_init, 100, EPS, sess)\n",
    "        print(\"done fitting em\")\n",
    "\n",
    "        observed = X_test[:len(train_ix)]\n",
    "        marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a, sess)\n",
    "\n",
    "        pred = argmax_exp(marginal_means, marginal_covs, marginal_alphas[0])[:len(unobserved_tested_ix)]\n",
    "        actual = X_test[len(train_ix):len(train_ix)+len(unobserved_tested_ix)]\n",
    "        print(len(pred), len(actual))\n",
    "        rmse = sklearn.metrics.mean_squared_error(actual, pred)\n",
    "        rmse_arr.append(rmse)\n",
    "        print('rmse', np.sqrt(rmse)) # rmse of GMM\n",
    "        r2 = sklearn.metrics.r2_score(actual, pred)\n",
    "        r2_arr.append(r2)\n",
    "        print('r2', r2)\n",
    "        sess.close()\n",
    "#     return rmse_arr, r2_arr\n",
    "    rmse_matrix[index, :] = rmse_arr\n",
    "    r2_matrix[index, :] = r2_arr\n",
    "\n",
    "# results = Parallel(n_jobs = 2)(delayed(get_avg_r2_cv)(K) for K in args_K)\n",
    "threads = [None] * len(args_K)\n",
    "for i in range(len(args_K)):\n",
    "    threads[i] = threading.Thread(target=get_avg_r2_cv, args=(args_K[i], i))\n",
    "    threads[i].start()\n",
    "for i in range(len(args_K)):\n",
    "    threads[i].join()\n",
    "    \n",
    "# i = 0\n",
    "# for K in args_K:\n",
    "#     print(\"K: \" + str(K))\n",
    "#     rmse_arr, r2_arr = get_avg_r2(K)\n",
    "#     rmse_matrix[i, :] = rmse_arr\n",
    "#     r2_matrix[i, :] = r2_arr\n",
    "#     i += 1\n",
    "    \n",
    "print(rmse_matrix)\n",
    "print(r2_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save RMSE / R^2\n",
    "np.save('cv_rmse', rmse_matrix)\n",
    "np.save('cv_r2', r2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01181451,  0.49466861,  0.01504508,  0.01638574,  0.01518659,\n",
       "         0.56034061,  0.01619131,  0.01332102,  0.01451038,  0.01450137,\n",
       "         0.48785416,  0.57519979,  0.66537731,  0.48272767,  0.50345909,\n",
       "         0.68704757,  0.49897608,  0.62765526,  0.55283239,  0.55880595,\n",
       "         0.01287547,  0.55201539,  0.01498285,  0.3703144 ,  0.50286533,\n",
       "         0.56881062,  0.57653486,  0.01450401],\n",
       "       [ 0.00931847,  0.49466861,  0.00855021,  0.01104168,  0.00829979,\n",
       "         0.56034061,  0.00910705,  0.00846965,  0.00617491,  0.01058723,\n",
       "         0.48785416,  0.01933833,  0.01144868,  0.51624171,  0.01938707,\n",
       "         0.68704757,  0.01679222,  0.62765526,  0.55283239,  0.55880595,\n",
       "         0.0075879 ,  0.55201539,  0.00841726,  0.3703144 ,  0.0196157 ,\n",
       "         0.01934769,  0.57653486,  0.01396652],\n",
       "       [ 0.00840094,  0.49466861,  0.00694016,  0.01137108,  0.00768767,\n",
       "         0.02823028,  0.00754357,  0.00604806,  0.00552677,  0.00868491,\n",
       "         0.01546147,  0.01634801,  0.01103736,  0.54028155,  0.02463585,\n",
       "         0.68704757,  0.01758082,  0.02081466,  0.0154741 ,  0.55880595,\n",
       "         0.00586698,  0.55201539,  0.00724525,  0.02989647,  0.50286533,\n",
       "         0.01967781,  0.57653486,  0.01533898],\n",
       "       [ 0.00817162,  0.49466861,  0.00717604,  0.01006877,  0.00768767,\n",
       "         0.02859078,  0.00664515,  0.00604806,  0.00514383,  0.01076885,\n",
       "         0.02394537,  0.01505497,  0.01111329,  0.59833882,  0.02463585,\n",
       "         0.68704757,  0.01679222,  0.02038475,  0.01858745,  0.02070382,\n",
       "         0.0064131 ,  0.55201539,  0.00538094,  0.02620674,  0.01735103,\n",
       "         0.01949873,  0.57653486,  0.01427295],\n",
       "       [ 0.00821528,  0.49466861,  0.00657602,  0.0119323 ,  0.00800435,\n",
       "         0.02918296,  0.00685222,  0.00558317,  0.00514383,  0.0087209 ,\n",
       "         0.48785416,  0.01544421,  0.01103736,  0.49750114,  0.01326037,\n",
       "         0.68704757,  0.0170791 ,  0.02056488,  0.02127925,  0.55880595,\n",
       "         0.00533345,  0.02034615,  0.00508728,  0.02769182,  0.01989622,\n",
       "         0.01992944,  0.57653486,  0.01497241],\n",
       "       [ 0.00842147,  0.49466861,  0.00672912,  0.01079603,  0.00732804,\n",
       "         0.0305066 ,  0.00757929,  0.00531734,  0.00526016,  0.00875422,\n",
       "         0.02040049,  0.01567487,  0.01081945,  0.49466861,  0.01861672,\n",
       "         0.68704757,  0.01977376,  0.0177198 ,  0.01858745,  0.02055712,\n",
       "         0.00545741,  0.55201539,  0.00606633,  0.0285363 ,  0.02314139,\n",
       "         0.01834325,  0.02157504,  0.01659277],\n",
       "       [ 0.00826898,  0.49466861,  0.00661105,  0.01240939,  0.00653482,\n",
       "         0.02918296,  0.00697158,  0.00594229,  0.00510985,  0.01052553,\n",
       "         0.01790494,  0.01482016,  0.01007568,  0.57319458,  0.01575959,\n",
       "         0.68704757,  0.02034355,  0.01505495,  0.01858745,  0.02075243,\n",
       "         0.00479763,  0.02034615,  0.00491342,  0.02477119,  0.01769832,\n",
       "         0.01807704,  0.57653486,  0.01497241],\n",
       "       [ 0.00786487,  0.49466861,  0.00551968,  0.01259749,  0.00647955,\n",
       "         0.02586751,  0.00809338,  0.00531734,  0.0053743 ,  0.01076885,\n",
       "         0.02051754,  0.01567487,  0.00884294,  0.57653486,  0.01326037,\n",
       "         0.68704757,  0.02306218,  0.01505495,  0.02402376,  0.55880595,\n",
       "         0.00437695,  0.02090383,  0.00557777,  0.02432893,  0.0244224 ,\n",
       "         0.02124509,  0.02166006,  0.01518581],\n",
       "       [ 0.00786487,  0.49466861,  0.00460434,  0.01072741,  0.00667587,\n",
       "         0.02586751,  0.00609688,  0.00612381,  0.00507801,  0.00933007,\n",
       "         0.02690309,  0.01235481,  0.01405272,  0.49466861,  0.01371759,\n",
       "         0.68704757,  0.02306218,  0.0226818 ,  0.02402376,  0.55880595,\n",
       "         0.00573765,  0.02034615,  0.00491342,  0.02519908,  0.0212148 ,\n",
       "         0.01727196,  0.02157504,  0.01482942]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
