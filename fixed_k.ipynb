{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idempotent data loading. For a given chromosome n (a string).\n",
      "    \n",
      "    Returns (train_df, test_df, train_ix, test_ix, train_tissues, tfs)\n",
      "    \n",
      "    The first two are the train and test dataframes, and test_ix are the\n",
      "    values in test_df['assayed'] that are missing and need to be imputed (with the\n",
      "    correct answer being in test_df['filled'] in the corresponding locations.\n",
      "    train_ix are the assayed (known) methylation values from limited microarray\n",
      "    sampling (e.g., test_df['assayed'].iloc[train_ix] can be used for prediction of\n",
      "    test_df['filled'].iloc[test_ix], and the former should be about equal to\n",
      "    test_df['filled'].iloc[train_ix] (two different ways of sampling methylation).\n",
      "    \n",
      "    Imports genetic context and adds those columns to the parameter df, returning\n",
      "    a merged one. tfs is the list of names of new transcription\n",
      "    factors.\n",
      "    \n",
      "    train_tissues is a list of the names of columns with chromosome methylation values.\n",
      "    \n",
      "    Note that loading from scratch may take ~5 min (for merging genetic contexts).\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import *\n",
    "import sklearn\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import scipy\n",
    "from joblib import Parallel, delayed\n",
    "import threading\n",
    "nproc = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "if 'utils' not in sys.path:\n",
    "    sys.path.append('utils')\n",
    "\n",
    "import data_loader\n",
    "from tf_gmm_em import *\n",
    "\n",
    "# Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Idempotent, cached data retrieval script\n",
    "\n",
    "print(data_loader.load_chromosome.__doc__)\n",
    "train_df, test_df, train_ix, test_ix, train_tissues, tfs = \\\n",
    "    data_loader.load_chromosome_cached('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df_int = train_df\n",
    "for i in train_tissues:\n",
    "    train_df_int[i] = data_loader.local_impute(train_df[i].copy())\n",
    "# print('nans in interpolated', np.isnan(train_df_int[train_tissues]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e82286b2ef54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmean_ll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnormal_likelihoods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mexponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# Make sure N, D are small so the numerically unstable verification code\n",
    "# doesn't underflow.\n",
    "N = 5\n",
    "D = 10\n",
    "\n",
    "X = np.random.normal(size=(N, D))\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "mus = np.array([mu, mu, mu * 2])\n",
    "sigmas = np.array([sigma, sigma * 2, sigma])\n",
    "K = len(sigmas)\n",
    "alphas = np.random.dirichlet(np.ones(K), 1)[0]\n",
    "\n",
    "mean_ll, resp = sess.run(estep(*(tf.constant(x) for x in (X, mus, sigmas, alphas))))\n",
    "def normal_likelihoods(X, mu, sigma):\n",
    "    exponent = -np.dot((X - mu[np.newaxis, :]) ** 2, 1 / sigma) / 2\n",
    "    return (2 * np.pi) ** (-D / 2) * np.prod(sigma) ** (-1 / 2) * np.exp(exponent)\n",
    "actual = np.array([normal_likelihoods(X, mu, sigma) for mu, sigma in zip(mus, sigmas)])\n",
    "actual = sklearn.preprocessing.normalize(actual * alphas[:, np.newaxis], norm='l1', axis=0)\n",
    "resp = sklearn.preprocessing.normalize(resp, norm='l1', axis=0)\n",
    "print('actual likelihoods', actual)\n",
    "print('log likelihoods   ', resp)\n",
    "rmses = np.sqrt(sklearn.metrics.mean_squared_error(actual.T, resp.T, multioutput='raw_values'))\n",
    "for i, rmse in enumerate(rmses):\n",
    "    print('K={} rmse={}'.format(i, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# N = 33\n",
    "# p = 20 # D is better?\n",
    "# K = 6\n",
    "# k = 0 # maximum band offset (0 is just diagonal)\n",
    "tissues_to_cluster = train_tissues\n",
    "X_np = train_df_int[train_tissues].values.transpose()\n",
    "\n",
    "# np.random.seed(2)\n",
    "# rc = np.random.choice(range(len(train_df)), D, replace=False)\n",
    "# rmu = np.random.choice(range(N), K, replace=False)\n",
    "\n",
    "# np.random.shuffle(X_np)\n",
    "# per = N // K\n",
    "# splits = [X_np[i:i+per] for i in range(0, N // K * K, per)]\n",
    "\n",
    "\n",
    "# X_trunc = X_np[:N, rc]\n",
    "# X_trunc = X_np[:N]\n",
    "# mu_init = X_trunc[rmu]\n",
    "# mu_init = np.array([x.mean(axis=0) for x in splits])\n",
    "#mu_init = X_np[19:22]\n",
    "# print(mu_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 379551)\n"
     ]
    }
   ],
   "source": [
    "print(X_np.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np.shape (34, 379551)\n",
      "(30, 379551)\n",
      "[  1084   1154   1214 ..., 378792 378806 379168]\n",
      "K 5\n",
      "NUM_RESTARTS 1\n",
      "X_perm.shape (30, 379551)\n",
      "Done picking best EM\n",
      "368411 368411\n",
      "rmse 0.0816920895421\n",
      "r2 0.766615879372\n",
      "[[-1728.81150894 -1766.86748946     0.         -1986.86303949\n",
      "  -1008.62999452]]\n"
     ]
    }
   ],
   "source": [
    "# Fix a value of K. Perform NUM_RESTARTS random restarts, and pick EM fit with highest mean likelihood \n",
    "# X_np_new = data matrix with bad samples deleted.\n",
    "# X_perm   = permute(X_np_new)\n",
    "# K        = number of clusters\n",
    "# NUM_RESTARTS = number of random restarts\n",
    "\n",
    "K = 5\n",
    "NUM_RESTARTS = 1\n",
    "\n",
    "def get_permutation():\n",
    "    o = np.ones(len(train_df))\n",
    "    o[train_ix] = 0\n",
    "    o[test_ix] = 0\n",
    "    unobserved_untested_ix = np.where(o)[0]\n",
    "    o = np.zeros(len(train_df))\n",
    "    o[test_ix] = 1\n",
    "    unobserved_tested_ix = np.where(o)[0]\n",
    "    permutation = np.hstack((train_ix, unobserved_tested_ix, unobserved_untested_ix))\n",
    "    return permutation, unobserved_tested_ix, unobserved_untested_ix\n",
    "\n",
    "def fit_model(X_train, unobserved_tested_ix, unobserved_untested_ix):\n",
    "    N = X_train.shape[0]\n",
    "    tf.reset_default_graph()\n",
    "    lp = None\n",
    "    m = None\n",
    "    s = None\n",
    "    a = None\n",
    "    for j in range(NUM_RESTARTS):\n",
    "        rmu = np.random.choice(range(X_train.shape[0]), K, replace=False)\n",
    "        mu_init = X_train[rmu]\n",
    "        cur_lp, cur_m, cur_s, cur_a = fit_em(X_train, mu_init, 100, EPS, 0.1)\n",
    "        if lp is None or cur_lp > lp:\n",
    "            lp = cur_lp\n",
    "            m = cur_m\n",
    "            s = cur_s\n",
    "            a = cur_a\n",
    "    print(\"Done picking best EM\")\n",
    "    \n",
    "    all_alphas = np.zeros((K, N))\n",
    "    for sample in range(N):\n",
    "        X_test = X_train[sample, :]\n",
    "        observed = X_test\n",
    "        marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a)\n",
    "        all_alphas[:, sample] = marginal_alphas.transpose()[:,0]\n",
    "        \n",
    "    \n",
    "    \n",
    "    observed = test_df['filled'][train_ix].values\n",
    "    marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a)\n",
    "\n",
    "    pred = argmax_exp(marginal_means, marginal_covs, marginal_alphas[0])[:len(unobserved_tested_ix)]\n",
    "    actual = test_df['filled'][unobserved_tested_ix]\n",
    "    print(len(pred), len(actual))\n",
    "    rmse = sklearn.metrics.mean_squared_error(actual, pred)\n",
    "    print('rmse', np.sqrt(rmse)) # rmse of GMM\n",
    "    r2 = sklearn.metrics.r2_score(actual, pred)\n",
    "    print('r2', r2)\n",
    "    return all_alphas, marginal_means, marginal_covs, marginal_alphas, lp, m, s, a\n",
    "    \n",
    "    \n",
    "'''\n",
    "    observed = X_test[:len(train_ix)]\n",
    "    marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a, sess)\n",
    "\n",
    "    pred = argmax_exp(marginal_means, marginal_covs, marginal_alphas[0])[:len(unobserved_tested_ix)]\n",
    "    actual = X_test[len(train_ix):len(train_ix)+len(unobserved_tested_ix)]\n",
    "    print(len(pred), len(actual))\n",
    "    \n",
    "    # Compute the rmse and r2\n",
    "    mse = sklearn.metrics.mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('rmse', rmse) # rmse of GMM\n",
    "    r2 = sklearn.metrics.r2_score(actual, pred)\n",
    "    print('r2', r2)\n",
    "'''\n",
    "\n",
    "print(\"X_np.shape\", X_np.shape) \n",
    "\n",
    "# delete bad samples\n",
    "X_np_new = X_np[:][:33]\n",
    "X_np_new = np.delete(X_np_new, [14,25,26], 0)\n",
    "print(X_np_new.shape)\n",
    "\n",
    "perm, unobserved_tested_ix, unobserved_untested_ix = get_permutation()\n",
    "print(perm)\n",
    "X_perm = X_np_new[:, perm]\n",
    "\n",
    "print(\"K\", K)\n",
    "print(\"NUM_RESTARTS\", NUM_RESTARTS)\n",
    "print(\"X_perm.shape\", X_perm.shape) \n",
    "\n",
    "#KxN responsibilities\n",
    "all_alphas, marginal_means, marginal_covs, marginal_alphas, marginal_logp, mus, sigs, alphas = fit_model(X_perm, unobserved_tested_ix, unobserved_untested_ix)\n",
    "print(marginal_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-34371.25051055 -36417.2580561  -37982.31618604 -39747.34410485\n",
      "  -43923.12738274 -51668.13070466 -50283.0206933  -44519.76572617\n",
      "  -25967.71717483 -20138.13803852 -30930.43369295 -47068.77734709\n",
      "  -14748.85333695 -24493.62938383 -15336.68869708  -8210.51786708\n",
      "  -25576.52869297      0.         -55380.57002862 -45198.52900181\n",
      "  -52256.08215395 -51096.70536267 -37602.73122082 -49561.32648987\n",
      "  -32733.26690678 -20580.66763318      0.         -19874.9379456\n",
      "  -47029.00398864 -30056.0241815 ]\n",
      " [     0.              0.              0.              0.         -46415.83846135\n",
      "  -55731.88471541 -53669.04180056 -46843.06351924 -46130.13978221      0.\n",
      "  -17053.4189288  -63929.61949275 -31095.42735754 -39633.52345225\n",
      "  -33699.01792111 -28907.73903501 -40678.01085388 -36269.35835991\n",
      "  -58775.321418   -47485.91086052 -54046.92890203 -54226.27344111\n",
      "  -41687.20946184 -50467.44136672 -37574.25566562 -23282.10151399\n",
      "  -45664.82831051 -37005.64314673 -49457.3853626  -19327.95225339]\n",
      " [-46529.56430162 -60019.16714314 -51907.50437011 -67596.43843889      0.\n",
      "       0.              0.              0.         -26019.69139848\n",
      "  -61232.70239188 -18427.02561405 -65765.7903504  -21592.30746276\n",
      "  -48910.78571726      0.              0.              0.         -55492.08991788\n",
      "       0.              0.              0.              0.              0.\n",
      "       0.              0.         -15962.62958355 -58161.1417471       0.\n",
      "       0.         -15795.99136823]\n",
      " [-58154.05751687 -60512.70949148 -62697.3118102  -63859.36189305\n",
      "  -52895.74944487 -61817.28688397 -60315.36484559 -57253.51839601      0.\n",
      "  -39242.49064799 -36202.1956452       0.          -5667.61591694      0.\n",
      "  -12399.26490022  -4402.08180519  -2300.24305385 -39817.63568908\n",
      "  -60463.97497997 -55401.50961638 -61030.38152386 -55471.82953653\n",
      "  -47982.53956055 -63280.61131466 -37110.44328105 -26573.29532807\n",
      "  -55538.37832755 -17704.68148975 -58003.43904666 -46071.4733036 ]\n",
      " [-32915.98934792 -44020.90996022 -38328.59194864 -50336.44025281\n",
      "  -24364.37852885 -29558.24385368 -29265.77565696 -28192.68665244\n",
      "  -31219.55825962 -46215.08064848      0.         -53738.75589113      0.\n",
      "  -36680.22568665 -19694.1018524  -16958.41533758 -21415.5022262\n",
      "  -48080.04964385 -30882.55060921 -26293.52421005 -28537.10040453\n",
      "  -28176.91814436 -24539.59303105 -27046.32008718 -17561.18632879      0.\n",
      "  -54077.52605016 -20115.89704908 -26888.63032235      0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(all_alphas)\n",
    "np.save('all_alphas.npy', all_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"mus\", mus)\n",
    "np.save(\"sigmas\", sigs)\n",
    "np.save(\"alphas\", alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(marginal_alphas.shape)\n",
    "print(marginal_covs.shape)\n",
    "print(marginal_means.shape)\n",
    "\n",
    "K = marginal_alphas.shape[1]\n",
    "\n",
    "print(\"before:\", np.sum(marginal_alphas))\n",
    "alphs = np.exp(marginal_alphas)\n",
    "print(\"after:\", np.sum(alphs))\n",
    "alphs = np.ndarray.tolist(alphs[0,:])\n",
    "\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# Pick a random clusters\n",
    "samples = np.random.choice(len(alphas), SAMPLE_SIZE, p=alphas)\n",
    "cnts = np.bincount(samples)\n",
    "print(cnts)\n",
    "\n",
    "print(marginal_means[1,:])\n",
    "\n",
    "#S = [] #np.zeros((SAMPLE_SIZE, 2))\n",
    "#for s in samples:\n",
    "    # Pick a sample from this normal\n",
    "    #np.random.normal(marginal_means[s,:], marginal_covs[s], size=(K,N))\n",
    "    \n",
    "    # Add the sample to the set of samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
