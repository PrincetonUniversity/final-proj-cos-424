{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idempotent data loading. For a given chromosome n (a string).\n",
      "    \n",
      "    Returns (train_df, test_df, train_ix, test_ix, train_tissues, tfs)\n",
      "    \n",
      "    The first two are the train and test dataframes, and test_ix are the\n",
      "    values in test_df['assayed'] that are missing and need to be imputed (with the\n",
      "    correct answer being in test_df['filled'] in the corresponding locations.\n",
      "    train_ix are the assayed (known) methylation values from limited microarray\n",
      "    sampling (e.g., test_df['assayed'].iloc[train_ix] can be used for prediction of\n",
      "    test_df['filled'].iloc[test_ix], and the former should be about equal to\n",
      "    test_df['filled'].iloc[train_ix] (two different ways of sampling methylation).\n",
      "    \n",
      "    Imports genetic context and adds those columns to the parameter df, returning\n",
      "    a merged one. tfs is the list of names of new transcription\n",
      "    factors.\n",
      "    \n",
      "    train_tissues is a list of the names of columns with chromosome methylation values.\n",
      "    \n",
      "    Note that loading from scratch may take ~5 min (for merging genetic contexts).\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import *\n",
    "import sklearn\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import multiprocessing\n",
    "import scipy\n",
    "from joblib import Parallel, delayed\n",
    "import threading\n",
    "nproc = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "if 'utils' not in sys.path:\n",
    "    sys.path.append('utils')\n",
    "\n",
    "import data_loader\n",
    "from tf_gmm_em import *\n",
    "\n",
    "# Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Idempotent, cached data retrieval script\n",
    "\n",
    "print(data_loader.load_chromosome.__doc__)\n",
    "train_df, test_df, train_ix, test_ix, train_tissues, tfs = \\\n",
    "    data_loader.load_chromosome_cached('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df_int = train_df\n",
    "for i in train_tissues:\n",
    "    train_df_int[i] = data_loader.local_impute(train_df[i].copy())\n",
    "# print('nans in interpolated', np.isnan(train_df_int[train_tissues]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual likelihoods [[ 0.26088298  0.29452575  0.0762016   0.30748466  0.45977218]\n",
      " [ 0.39989859  0.22567318  0.37302021  0.3812018   0.1812242 ]\n",
      " [ 0.33921843  0.47980106  0.5507782   0.31131355  0.35900362]]\n",
      "log likelihoods    [[ 0.26088298  0.29452575  0.0762016   0.30748466  0.45977218]\n",
      " [ 0.39989859  0.22567318  0.37302021  0.3812018   0.1812242 ]\n",
      " [ 0.33921843  0.47980106  0.5507782   0.31131355  0.35900362]]\n",
      "K=0 rmse=3.2676223177844214e-16\n",
      "K=1 rmse=2.9634845277824204e-16\n",
      "K=2 rmse=3.466670283279959e-16\n"
     ]
    }
   ],
   "source": [
    "# Make sure N, D are small so the numerically unstable verification code\n",
    "# doesn't underflow.\n",
    "N = 5\n",
    "D = 10\n",
    "\n",
    "X = np.random.normal(size=(N, D))\n",
    "mu = X.mean(axis=0)\n",
    "sigma = X.std(axis=0)\n",
    "mus = np.array([mu, mu, mu * 2])\n",
    "sigmas = np.array([sigma, sigma * 2, sigma])\n",
    "K = len(sigmas)\n",
    "alphas = np.random.dirichlet(np.ones(K), 1)[0]\n",
    "\n",
    "mean_ll, resp = sess.run(estep(*(tf.constant(x) for x in (X, mus, sigmas, alphas))))\n",
    "def normal_likelihoods(X, mu, sigma):\n",
    "    exponent = -np.dot((X - mu[np.newaxis, :]) ** 2, 1 / sigma) / 2\n",
    "    return (2 * np.pi) ** (-D / 2) * np.prod(sigma) ** (-1 / 2) * np.exp(exponent)\n",
    "actual = np.array([normal_likelihoods(X, mu, sigma) for mu, sigma in zip(mus, sigmas)])\n",
    "actual = sklearn.preprocessing.normalize(actual * alphas[:, np.newaxis], norm='l1', axis=0)\n",
    "resp = sklearn.preprocessing.normalize(resp, norm='l1', axis=0)\n",
    "print('actual likelihoods', actual)\n",
    "print('log likelihoods   ', resp)\n",
    "rmses = np.sqrt(sklearn.metrics.mean_squared_error(actual.T, resp.T, multioutput='raw_values'))\n",
    "for i, rmse in enumerate(rmses):\n",
    "    print('K={} rmse={}'.format(i, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# N = 33\n",
    "# p = 20 # D is better?\n",
    "# K = 6\n",
    "# k = 0 # maximum band offset (0 is just diagonal)\n",
    "tissues_to_cluster = train_tissues\n",
    "X_np = train_df_int[train_tissues].values.transpose()\n",
    "\n",
    "# np.random.seed(2)\n",
    "# rc = np.random.choice(range(len(train_df)), D, replace=False)\n",
    "# rmu = np.random.choice(range(N), K, replace=False)\n",
    "\n",
    "# np.random.shuffle(X_np)\n",
    "# per = N // K\n",
    "# splits = [X_np[i:i+per] for i in range(0, N // K * K, per)]\n",
    "\n",
    "\n",
    "# X_trunc = X_np[:N, rc]\n",
    "# X_trunc = X_np[:N]\n",
    "# mu_init = X_trunc[rmu]\n",
    "# mu_init = np.array([x.mean(axis=0) for x in splits])\n",
    "#mu_init = X_np[19:22]\n",
    "# print(mu_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 379551)\n"
     ]
    }
   ],
   "source": [
    "print(X_np.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np.shape (34, 379551)\n",
      "(30, 379551)\n",
      "[  1084   1154   1214 ..., 378792 378806 379168]\n",
      "K 5\n",
      "NUM_RESTARTS 1\n",
      "X_perm.shape (30, 379551)\n"
     ]
    }
   ],
   "source": [
    "# Fix a value of K. Perform NUM_RESTARTS random restarts, and pick EM fit with highest mean likelihood \n",
    "# X_np_new = data matrix with bad samples deleted.\n",
    "# X_perm   = permute(X_np_new)\n",
    "# K        = number of clusters\n",
    "# NUM_RESTARTS = number of random restarts\n",
    "\n",
    "K = 5\n",
    "NUM_RESTARTS = 1\n",
    "\n",
    "def get_permutation():\n",
    "    o = np.ones(len(train_df))\n",
    "    o[train_ix] = 0\n",
    "    o[test_ix] = 0\n",
    "    unobserved_untested_ix = np.where(o)[0]\n",
    "    o = np.zeros(len(train_df))\n",
    "    o[test_ix] = 1\n",
    "    unobserved_tested_ix = np.where(o)[0]\n",
    "    permutation = np.hstack((train_ix, unobserved_tested_ix, unobserved_untested_ix))\n",
    "    return permutation, unobserved_tested_ix, unobserved_untested_ix\n",
    "\n",
    "def fit_model(X_train, unobserved_tested_ix, unobserved_untested_ix):\n",
    "    tf.reset_default_graph()\n",
    "    lp = None\n",
    "    m = None\n",
    "    s = None\n",
    "    a = None\n",
    "    for j in range(NUM_RESTARTS):\n",
    "        rmu = np.random.choice(range(X_train.shape[0]), K, replace=False)\n",
    "        mu_init = X_train[rmu]\n",
    "        cur_lp, cur_m, cur_s, cur_a = fit_em(X_train, mu_init, 100, EPS)\n",
    "        if lp is None or cur_lp > lp:\n",
    "            lp = cur_lp\n",
    "            m = cur_m\n",
    "            s = cur_s\n",
    "            a = cur_a\n",
    "    print(\"Done picking best EM\")\n",
    "    \n",
    "    # X is NxD, mus is KxD, sigmas KxD, alphas is K\n",
    "    # output is 1xN log probability for each sample, KxN responsibilities\n",
    "\n",
    "    observed = test_df['filled'][train_ix].values\n",
    "    marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a)\n",
    "\n",
    "    pred = argmax_exp(marginal_means, marginal_covs, marginal_alphas[0])[:len(unobserved_tested_ix)]\n",
    "    actual = test_df['filled'][unobserved_tested_ix]\n",
    "    print(len(pred), len(actual))\n",
    "    rmse = sklearn.metrics.mean_squared_error(actual, pred)\n",
    "    print('rmse', np.sqrt(rmse)) # rmse of GMM\n",
    "    r2 = sklearn.metrics.r2_score(actual, pred)\n",
    "    print('r2', r2)\n",
    "    return marginal_means, marginal_covs, marginal_alphas, lp, m, s, a\n",
    "    \n",
    "    \n",
    "'''\n",
    "    observed = X_test[:len(train_ix)]\n",
    "    marginal_means, marginal_covs, marginal_alphas = marginal_posterior(observed.reshape(1, len(observed)), m, s, a, sess)\n",
    "\n",
    "    pred = argmax_exp(marginal_means, marginal_covs, marginal_alphas[0])[:len(unobserved_tested_ix)]\n",
    "    actual = X_test[len(train_ix):len(train_ix)+len(unobserved_tested_ix)]\n",
    "    print(len(pred), len(actual))\n",
    "    \n",
    "    # Compute the rmse and r2\n",
    "    mse = sklearn.metrics.mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('rmse', rmse) # rmse of GMM\n",
    "    r2 = sklearn.metrics.r2_score(actual, pred)\n",
    "    print('r2', r2)\n",
    "'''\n",
    "\n",
    "print(\"X_np.shape\", X_np.shape) \n",
    "\n",
    "# delete bad samples\n",
    "X_np_new = X_np[:][:33]\n",
    "X_np_new = np.delete(X_np_new, [14,25,26], 0)\n",
    "print(X_np_new.shape)\n",
    "\n",
    "perm, unobserved_tested_ix, unobserved_untested_ix = get_permutation()\n",
    "print(perm)\n",
    "X_perm = X_np_new[:, perm]\n",
    "\n",
    "print(\"K\", K)\n",
    "print(\"NUM_RESTARTS\", NUM_RESTARTS)\n",
    "print(\"X_perm.shape\", X_perm.shape) \n",
    "\n",
    "#KxN responsibilities\n",
    "marginal_means, marginal_covs, marginal_alphas, marginal_logp, mus, sigs, alphas = fit_model(X_perm, unobserved_tested_ix, unobserved_untested_ix)\n",
    "print(marginal_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(5, 372028)\n",
      "(5, 372028)\n",
      "before: -8801.12989189\n",
      "after: 1.0\n",
      "[14 39 41  4  2]\n",
      "[ 0.91995043  0.93998369  0.92546759 ...,  0.19855093  0.76246235\n",
      "  0.91682623]\n"
     ]
    }
   ],
   "source": [
    "print(marginal_alphas.shape)\n",
    "print(marginal_covs.shape)\n",
    "print(marginal_means.shape)\n",
    "\n",
    "K = marginal_alphas.shape[1]\n",
    "\n",
    "print(\"before:\", np.sum(marginal_alphas))\n",
    "alphs = np.exp(marginal_alphas)\n",
    "print(\"after:\", np.sum(alphs))\n",
    "alphs = np.ndarray.tolist(alphs[0,:])\n",
    "\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# Pick a random clusters\n",
    "samples = np.random.choice(len(alphas), SAMPLE_SIZE, p=alphas)\n",
    "cnts = np.bincount(samples)\n",
    "print(cnts)\n",
    "\n",
    "print(marginal_means[1,:])\n",
    "\n",
    "#S = [] #np.zeros((SAMPLE_SIZE, 2))\n",
    "#for s in samples:\n",
    "    # Pick a sample from this normal\n",
    "    #np.random.normal(marginal_means[s,:], marginal_covs[s], size=(K,N))\n",
    "    \n",
    "    # Add the sample to the set of samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
